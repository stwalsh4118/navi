# [12-4] Research Claude Code hook environment

[Back to task list](./tasks.md)

## Description

Investigate what data is available from Claude Code hooks for metrics collection. This research task will determine what token counts, tool usage data, and other metrics can be captured from environment variables, hook arguments, or Claude Code output.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2026-02-05 16:25:14 | Created | N/A | Proposed | Task file created | AI_Agent |
| 2026-02-05 16:36:53 | Status Change | Proposed | InProgress | Started research | AI_Agent |
| 2026-02-05 16:37:45 | Status Change | InProgress | Review | Research complete, findings documented | AI_Agent |
| 2026-02-05 18:31:18 | Status Change | Review | Done | Task completed and verified | AI_Agent |

## Requirements

- Research Claude Code hook system documentation
- Identify available environment variables during hook execution
- Determine if token counts are exposed (input/output tokens)
- Determine if tool usage events are available (ToolUse hook or similar)
- Document findings for implementation in subsequent tasks

## Implementation Plan

1. Review Claude Code documentation for hooks:
   - Check official documentation at https://docs.anthropic.com/claude-code
   - Review hook types: UserPromptSubmit, Stop, PermissionRequest, SessionEnd
   - Check for additional hooks like ToolUse, ModelResponse, etc.
2. Create test hook script to log all available environment variables:
   ```bash
   #!/bin/bash
   env > /tmp/claude-hook-env-$1.log
   echo "Args: $@" >> /tmp/claude-hook-env-$1.log
   ```
3. Configure test hook and trigger each hook type
4. Analyze captured data for:
   - CLAUDE_INPUT_TOKENS / CLAUDE_OUTPUT_TOKENS
   - CLAUDE_TOOL_NAME / CLAUDE_TOOL_CALLS
   - Any other relevant metrics
5. Document findings in this task file under a new "Research Findings" section
6. Create guide document if significant external API discovered

## Test Plan

**Research task - documentation deliverable:**

- Successfully capture environment variables from all hook types
- Document all relevant environment variables found
- Identify feasibility of token and tool tracking
- Create implementation recommendations

## Verification

- [ ] Hook environment documented
- [ ] Token availability determined
- [ ] Tool tracking feasibility determined
- [ ] Research findings documented in this file
- [ ] Implementation recommendations provided

## Research Findings

### Summary

Based on research of the Claude Code hook system documentation, here are the key findings:

### Environment Variables Available in Hooks

All hooks receive JSON input via stdin containing:
- `session_id` - Unique session identifier
- `transcript_path` - Path to conversation JSON
- `cwd` - Current working directory
- `permission_mode` - Current permission mode
- `hook_event_name` - Name of the event that fired

**SessionStart hooks only**:
- `CLAUDE_ENV_FILE` - File path for persisting environment variables

### Token Counts - NOT Available in Hooks

**Critical finding**: Token counts (input/output) are **NOT exposed through the hooks system**.

Token data is only available through:
- **OpenTelemetry Metrics** - Requires external telemetry backend (Prometheus, OTLP)
- **API request events** (`claude_code.api_request`) - Contains input_tokens, output_tokens, but only in telemetry

### Tool Usage Events - Partially Available

Hooks DO receive tool-related data for specific events:
- **PreToolUse**: `tool_name`, `tool_input`, `tool_use_id`
- **PostToolUse**: `tool_name`, `tool_input`, `tool_response`, `tool_use_id`

However, this is the tool input/output data, not aggregated metrics.

### Data Availability Summary

| Data Type | Available in Hooks | Notes |
|-----------|-------------------|-------|
| Session ID | Yes | JSON input |
| Current directory | Yes | JSON input |
| Tool name | Yes | Event-specific |
| Tool input/output | Yes | Event-specific |
| **Input tokens** | **No** | OpenTelemetry only |
| **Output tokens** | **No** | OpenTelemetry only |
| Aggregated tool counts | **No** | Must track manually |

### Implementation Recommendations

Given these limitations, the recommended approach for PBI-12 is:

1. **Time Tracking** - Fully implementable using timestamps in hooks
2. **Tool Activity** - Track tool usage by:
   - Adding hooks for `PreToolUse` or `PostToolUse` events
   - Manually accumulating counts in the session JSON
   - Maintaining a "recent tools" list
3. **Token Tracking** - Options:
   - **Option A (Recommended)**: Don't track tokens (data not available)
   - **Option B**: Enable OpenTelemetry and query metrics backend (complex setup)
   - **Option C**: Parse transcript file for rough estimates (unreliable)

### Conclusion

Token tracking is not feasible without OpenTelemetry infrastructure. Tool tracking is achievable by adding PreToolUse/PostToolUse hooks and manually accumulating counts. Time tracking is fully implementable.

## Files Modified

- This task file updated with research findings
