# [55-4] Concurrent Provider Execution

[Back to task list](./tasks.md)

## Description

Optimize `taskRefreshCmd` to execute task providers concurrently with bounded concurrency instead of sequentially. Currently, `taskRefreshCmd` iterates over project configs in a loop and executes each provider one at a time. With many projects, this adds up to significant latency (each provider script can take seconds). This task introduces bounded concurrency (e.g., semaphore of 4) so multiple providers execute in parallel while preserving cache behavior and deterministic result assembly.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2026-02-18 08:00:46 | Created | N/A | Proposed | Task file created | AI_Agent |

## Requirements

1. Provider scripts for different projects execute concurrently, bounded by a configurable concurrency limit.
2. Cache check remains per-project: cached results skip provider execution (no change to cache semantics).
3. Results are assembled deterministically — the output `tasksMsg` must be identical regardless of execution order.
4. Provider timeout behavior is preserved per-provider (each gets its own context timeout).
5. Error handling per-project is preserved — one project's failure must not affect others.
6. The concurrency limit should be a named constant (e.g., `maxProviderConcurrency = 4`).
7. No changes to the `ProviderResult`, `tasksMsg`, or cache types — only the execution strategy changes.

## Implementation Plan

1. In `tasks.go`, modify `taskRefreshCmd` to use a goroutine pool pattern.
2. First pass: separate cached results from non-cached configs.
3. For non-cached configs, launch goroutines with a semaphore channel of size `maxProviderConcurrency`.
4. Each goroutine executes `task.ExecuteProvider(cfg, timeout)`, updates cache, and writes to a result channel or protected map.
5. Collect all results (cached + freshly-executed) and assemble the final `tasksMsg`.
6. Use `sync.Mutex` or pre-allocated result slices indexed by config position to avoid data races.
7. Ensure `normalizeGroups` is called after collection (it's stateless and safe to call per-result).

## Test Plan

### Objectives
Verify concurrent execution preserves correctness and improves throughput.

### Test Scope
- Unit tests in `internal/tui/` for the modified `taskRefreshCmd`.

### Key Scenarios
1. **Single project**: Behavior identical to sequential — one provider executed, result returned.
2. **Multiple projects, all cached**: No providers executed, cached results returned immediately.
3. **Multiple projects, none cached**: All providers execute concurrently; results match expected output.
4. **Mixed cached/uncached**: Cached results returned alongside fresh executions.
5. **Provider error**: One project errors, others succeed; error isolated to the failing project.
6. **Concurrency limit**: With more projects than `maxProviderConcurrency`, execution proceeds in batches without deadlock.

### Success Criteria
- All existing task refresh tests pass without modification.
- No data races detected by `go test -race`.
- Results are deterministic across multiple runs.

## Verification

_To be filled during implementation._

## Files Modified

_To be filled during implementation._
